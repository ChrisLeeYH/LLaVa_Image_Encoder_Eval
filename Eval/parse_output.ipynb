{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the output files to extract all ratings and the average ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_ratings(jsonl_files, ratings_excel, avg_ratings_excel, rating_columns, avg_columns):\n",
    "    \"\"\"\n",
    "    Read JSONL files and extract information.\n",
    "\n",
    "    :param jsonl_files: model-generated output files in string formats.\n",
    "    :param ratings_excel: excel file to save all model-generated ratings.\n",
    "    :param avg_ratings_exlce: excle file to save the average ratings of each image across different rating aspects.\n",
    "    :param rating_columns, avg_columns: customized column names.\n",
    "\n",
    "    :return: two xlsx files recording all rating data and avegrage data respectively.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for idx, jsonl_file in enumerate(jsonl_files):\n",
    "        data = []\n",
    "        with open(jsonl_file, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                entry = json.loads(line.strip())\n",
    "                image_name = entry[\"image_path\"].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "                \n",
    "                matches = re.findall(r\"Rating:\\s*(\\d+)\", entry[\"output\"])\n",
    "                ratings = [int(m) for m in matches] if matches else [None] * 10 \n",
    "                \n",
    "                for rating in ratings:\n",
    "                    data.append([image_name, rating])\n",
    "        \n",
    "        df = pd.DataFrame(data, columns=[\"image\", rating_columns[idx]])\n",
    "        all_data.append(df)\n",
    "    \n",
    "    # Concatenate data from all JSONL files\n",
    "    ratings_df = pd.concat(all_data, axis=1)\n",
    "    ratings_df = ratings_df.loc[:, ~ratings_df.columns.duplicated()]\n",
    "    \n",
    "    # Compute average rating per image for each rating column\n",
    "    avg_df = ratings_df.groupby(\"image\", as_index=False).mean()\n",
    "    avg_df.columns = [\"image\"] + avg_columns\n",
    "    \n",
    "    # Save\n",
    "    ratings_df.to_excel(ratings_excel, index=False)\n",
    "    avg_df.to_excel(avg_ratings_excel, index=False)\n",
    "    print(f\"Results saved to {ratings_excel} and {avg_ratings_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\parsed_output_all_320_temperature_0.3\\Output_LLaVa_Ratings_all_320.xlsx and C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\parsed_output_all_320_temperature_0.3\\Output_LLaVa_Avg_Ratings_all_320.xlsx\n"
     ]
    }
   ],
   "source": [
    "extract_ratings(\n",
    "    [\n",
    "        r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\output_all_320_temperature_0.3\\output_Relevance_all_320.jsonl\", \n",
    "        r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\output_all_320_temperature_0.3\\output_Arousal_all_320.jsonl\", \n",
    "        r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\output_all_320_temperature_0.3\\output_Valence_all_320.jsonl\"\n",
    "    ], \n",
    "    r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\parsed_output_all_320_temperature_0.3\\Output_LLaVa_Ratings_all_320.xlsx\", \n",
    "    r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\parsed_output_all_320_temperature_0.3\\Output_LLaVa_Avg_Ratings_all_320.xlsx\", \n",
    "    [\"Relevance\", \"Arousal\", \"Valence\"], \n",
    "    [\"Avg_Relevance\", \"Avg_Arousal\", \"Avg_Valence\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the average ratings file with human-encoded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_xlsx_columns(avg_ratings_file, raw_data_file, output_file):\n",
    "    \"\"\"\n",
    "    Merge the raw data and the model-generated data\n",
    "\n",
    "    :param avg_ratings_file: model-generated data\n",
    "    :param raw_data_file: raw data (human encoded)\n",
    "    :param output_file: merged data\n",
    "\n",
    "    :return: a merged xlsx file.\n",
    "    \"\"\"\n",
    "    avg_ratings_df = pd.read_excel(avg_ratings_file)\n",
    "    \n",
    "    raw_data_df = pd.read_excel(raw_data_file)\n",
    "    \n",
    "    # Ensure the number of raws match\n",
    "    if avg_ratings_df.shape[0] != raw_data_df.shape[0]:\n",
    "        raise ValueError(\"No match.\")\n",
    "    \n",
    "    # Copy columns\n",
    "    avg_ratings_df[[\"Raw_Avg_Relevance\", \"Raw_Avg_Arousal\", \"Raw_Avg_Valence\"]] = raw_data_df.iloc[:, 1:4].values\n",
    "    \n",
    "    # Save\n",
    "    avg_ratings_df.to_excel(output_file, index=False)\n",
    "    print(f\"Merged file saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved as C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\merged_avg_ratings_llava_human_all_320.xlsx\n"
     ]
    }
   ],
   "source": [
    "merge_xlsx_columns(\n",
    "    r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\parsed_output_all_320_temperature_0.3\\Output_LLaVa_Avg_Ratings_all_320.xlsx\", \n",
    "    r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\Raw\\aci_database_image_ratings.xlsx\", \n",
    "    r\"C:\\Users\\86158\\Desktop\\Research\\LlaVa_Image_Encoder_Eval\\Data\\with_temperature\\merged_avg_ratings_llava_human_all_320.xlsx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
